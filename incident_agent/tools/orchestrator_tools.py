# incident_agent/tools/orchestrator_tools.py

from google.adk.tools.tool_context import ToolContext
from . import data_loaders, detectors
import re

def recolectar_informacion_tool(date_str: str, tool_context: ToolContext) -> str:
    """
    Herramienta del RecolectorAgent. Carga y PARSEA todos los datos necesarios
    y los guarda en la memoria de la sesi√≥n (state).
    """
    print("--- üì£ Agente 1 (Recolector): Iniciando recolecci√≥n de datos... ---")
    try:
        daily_files_path = f"data/{date_str}_20_00_UTC/files.json"
        daily_files_df = data_loaders.process_files_json(daily_files_path, date_str)
        tool_context.state['daily_files_df'] = daily_files_df

        all_source_ids = data_loaders.get_all_source_ids()
        tool_context.state['all_source_ids'] = all_source_ids

        # --- L√ìGICA DE CARGA CENTRALIZADA Y EFICIENTE ---
        cv_data_map = {}
        source_to_workspace_map = {}
        print("--- üì£ Agente 1: Iniciando parseo de todas las Hojas de Vida... ---")
        for source_id in all_source_ids:
            # Leemos el archivo UNA SOLA VEZ, obteniendo tablas y texto
            parsed_tables, cv_text = data_loaders.parse_cv_data_and_text(source_id)
            
            # Guardamos las tablas (incluso si est√°n vac√≠as, para que el detector no falle)
            cv_data_map[source_id] = parsed_tables
            
            # Extraemos el Workspace ID del texto original
            match = re.search(r'Workspace ID\s*:\s*(\d+)', cv_text)
            if match:
                source_to_workspace_map[source_id] = match.group(1)
            else:
                source_to_workspace_map[source_id] = "Desconocido"
        
        tool_context.state['cv_data_map'] = cv_data_map
        tool_context.state['source_to_workspace_map'] = source_to_workspace_map

        log_message = f"Agente 1 (Recolector) carg√≥ y proces√≥ datos para {len(all_source_ids)} recursos."
        print(f"--- ‚úÖ {log_message} ---")
        tool_context.state['date_str'] = date_str
        return log_message
    except Exception as e:
        return f"Error durante la recolecci√≥n de datos: {e}"

def ejecutar_ciclo_deteccion_tool(tool_context: ToolContext) -> str:
    """
    Herramienta del DetectorAgent. LEE los datos YA PROCESADOS de la memoria,
    itera y ejecuta los detectores.
    """
    print("\n--- üì£ Agente 2 (Detector): Iniciando ciclo de detecci√≥n... ---")
    try:
        daily_files_df = tool_context.state.get('daily_files_df')
        all_source_ids = tool_context.state.get('all_source_ids')
        cv_data_map = tool_context.state.get('cv_data_map') # Lee el mapa de CVs pre-procesado
        date_str = tool_context.state.get('date_str')

        if daily_files_df is None or all_source_ids is None or cv_data_map is None:
            return "Error: Datos necesarios no encontrados en memoria."

        all_incidents = []
        for source_id in all_source_ids:
            cv_data = cv_data_map.get(source_id)
            
            # Ahora, en lugar de omitir, solo verificamos si el CV existe en el mapa
            if cv_data is None:
                print(f"--- ‚ö†Ô∏è Agente 2: Omitiendo fuente {source_id} (no se encontr√≥ en el mapa de CVs). ---")
                continue
            
            print(f"--- üïµÔ∏è Agente 2: Analizando fuente {source_id}... ---")
            
            missing_incidents = detectors.find_missing_files(daily_files_df, cv_data, source_id, date_str)
            if missing_incidents:
                 print(f"--- ‚ùó Agente 2: 'Missing Files' encontr√≥ {len(missing_incidents)} incidencia(s) para {source_id}. ---")
                 all_incidents.extend(missing_incidents)
        
        tool_context.state['all_incidents'] = all_incidents
        log_message = f"Agente 2 (Detector) ha consolidado {len(all_incidents)} incidencias."
        print(f"--- ‚úÖ {log_message} ---")
        return log_message
    except Exception as e:
        return f"Error durante el ciclo de detecci√≥n: {e}"

def generar_reporte_final_tool(tool_context: ToolContext) -> str:
    # ... (Esta funci√≥n se queda exactamente igual)
    print("\n--- üì£ Agente 3 (Redactor): Iniciando generaci√≥n de reporte... ---")
    try:
        all_incidents = tool_context.state.get('all_incidents', [])
        source_to_workspace_map = tool_context.state.get('source_to_workspace_map', {})
        if not all_incidents:
            report = {}
            tool_context.state['final_report'] = report
            return "Reporte generado: No se encontraron incidencias."
        report_by_workspace = {}
        for incident in all_incidents:
            source_id = incident.get('source_id')
            workspace_id = source_to_workspace_map.get(str(source_id), f"Workspace_de_{source_id}")
            if workspace_id not in report_by_workspace: report_by_workspace[workspace_id] = []
            report_by_workspace[workspace_id].append(incident)
        tool_context.state['final_report'] = report_by_workspace
        log_message = f"Agente 3 (Redactor) cre√≥ el reporte para {len(report_by_workspace)} workspace(s)."
        print(f"--- ‚úÖ {log_message} ---")
        return log_message
    except Exception as e: return f"Error durante la generaci√≥n del reporte: {e}"